{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e1f30d400b17715",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Importing necessary libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d26d1040448a63",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "id": "5b670febfdf20410",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-04-10T22:43:07.644004Z",
     "start_time": "2024-04-10T22:43:07.349401Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from distilbert_model import DistilBertModel\n",
    "from bert_model import BertModel\n",
    "from roberta_model import RobertaModel\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from .autonotebook import tqdm\n",
    "from plot import plot_roc_curve\n",
    "from ToxicCommentsDataset import ToxicCommentsDataset\n"
   ],
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.distilbert.tokenization_distilbert_fast because of the following error (look up to see its traceback):\nNo module named 'Distilbert'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "File \u001B[0;32m/mnt/d/CMPT413/nlpclass-1241-g-teamthinkers/jigsaw-toxic-comment-classification/venv/lib/python3.10/site-packages/transformers/utils/import_utils.py:905\u001B[0m, in \u001B[0;36m_LazyModule._get_module\u001B[0;34m(self, module_name)\u001B[0m\n\u001B[1;32m    904\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 905\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimportlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m.\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmodule_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__name__\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    906\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m/usr/lib/python3.10/importlib/__init__.py:126\u001B[0m, in \u001B[0;36mimport_module\u001B[0;34m(name, package)\u001B[0m\n\u001B[1;32m    125\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m--> 126\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1050\u001B[0m, in \u001B[0;36m_gcd_import\u001B[0;34m(name, package, level)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1027\u001B[0m, in \u001B[0;36m_find_and_load\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1006\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:688\u001B[0m, in \u001B[0;36m_load_unlocked\u001B[0;34m(spec)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap_external>:883\u001B[0m, in \u001B[0;36mexec_module\u001B[0;34m(self, module)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:241\u001B[0m, in \u001B[0;36m_call_with_frames_removed\u001B[0;34m(f, *args, **kwds)\u001B[0m\n",
      "File \u001B[0;32m/mnt/d/CMPT413/nlpclass-1241-g-teamthinkers/jigsaw-toxic-comment-classification/venv/lib/python3.10/site-packages/transformers/models/distilbert/tokenization_distilbert_fast.py:18\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m logging\n\u001B[0;32m---> 18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbert\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtokenization_bert_fast\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BertTokenizerFast\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtokenization_distilbert\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DistilBertTokenizer\n",
      "File \u001B[0;32m/mnt/d/CMPT413/nlpclass-1241-g-teamthinkers/jigsaw-toxic-comment-classification/venv/lib/python3.10/site-packages/transformers/models/bert/tokenization_bert_fast.py:22\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtokenizers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m normalizers\n\u001B[0;32m---> 22\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mDistilbert\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtokenization_utils_fast\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PreTrainedTokenizerFast\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'Distilbert'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m train_test_split\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m accuracy_score, precision_recall_fscore_support\n\u001B[0;32m---> 10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdistilbert_model\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DistilBertModel\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mbert_model\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BertModel\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mroberta_model\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RobertaModel\n",
      "File \u001B[0;32m/mnt/d/CMPT413/nlpclass-1241-g-teamthinkers/jigsaw-toxic-comment-classification/distilbert_model.py:3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Assuming base_model.py and distilbert_model.py are in the same directory\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mbase_model\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BaseModel\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mToxicCommentsDataset\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ToxicCommentsDataset  \u001B[38;5;66;03m# Ensure this import statement works based on your project structure\u001B[39;00m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1075\u001B[0m, in \u001B[0;36m_handle_fromlist\u001B[0;34m(module, fromlist, import_, recursive)\u001B[0m\n",
      "File \u001B[0;32m/mnt/d/CMPT413/nlpclass-1241-g-teamthinkers/jigsaw-toxic-comment-classification/venv/lib/python3.10/site-packages/transformers/utils/import_utils.py:896\u001B[0m, in \u001B[0;36m_LazyModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m    894\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_class_to_module\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m    895\u001B[0m     module \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_module(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_class_to_module[name])\n\u001B[0;32m--> 896\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    897\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    898\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodule \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m has no attribute \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/mnt/d/CMPT413/nlpclass-1241-g-teamthinkers/jigsaw-toxic-comment-classification/venv/lib/python3.10/site-packages/transformers/utils/import_utils.py:895\u001B[0m, in \u001B[0;36m_LazyModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m    893\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_module(name)\n\u001B[1;32m    894\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_class_to_module\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m--> 895\u001B[0m     module \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_class_to_module\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    896\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(module, name)\n\u001B[1;32m    897\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m/mnt/d/CMPT413/nlpclass-1241-g-teamthinkers/jigsaw-toxic-comment-classification/venv/lib/python3.10/site-packages/transformers/utils/import_utils.py:907\u001B[0m, in \u001B[0;36m_LazyModule._get_module\u001B[0;34m(self, module_name)\u001B[0m\n\u001B[1;32m    905\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m importlib\u001B[38;5;241m.\u001B[39mimport_module(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m module_name, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[1;32m    906\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m--> 907\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    908\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to import \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodule_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m because of the following error (look up to see its\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    909\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m traceback):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    910\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Failed to import transformers.models.distilbert.tokenization_distilbert_fast because of the following error (look up to see its traceback):\nNo module named 'Distilbert'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "6966095c3b0abbfc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Defining Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd40503561a937bd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "label_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "model_dir = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809debaaad804fc2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Selecting the model, please select the model from the following list:\n",
    "1. DistilBERT\n",
    "2. BERT\n",
    "3. RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c631ea44b4377d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "selection = input(\"Please select the model from the following list: \\n1. DistilBERT\\n2. BERT\\n3. RoBERTa\\n\")\n",
    "if selection == '1':\n",
    "    model = DistilBertModel(num_labels=6)\n",
    "    model_dir = \"./DistilbertModel\"\n",
    "elif selection == '2':\n",
    "    model = BertModel(num_labels=6)\n",
    "    model_dir = \"./BertModel\"\n",
    "elif selection == '3':\n",
    "    model = RobertaModel(num_labels=6)\n",
    "    model_dir = \"./RobertaModel\"\n",
    "else:\n",
    "    print(\"Defaulting to DistilBERT\")\n",
    "    model = DistilBertModel(num_labels=6)\n",
    "    model_dir = \"./DistilbertModel\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea05cf03a21370c8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Loading and pre-processing the train dataset. Pre-processing is done within the dataset class, defined in the train function of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9d4df410260569",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dataset_path = \"data/input/train.csv\"\n",
    "\n",
    "df = pd.read_csv(dataset_path)\n",
    "train_df, val_df = train_test_split(df, test_size=0.1)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179d2b39aa573bd5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(self, text):\n",
    "    \"\"\"Custom text cleaning function.\"\"\"\n",
    "    # Replace URLs\n",
    "    text = re.sub(r'http\\S+', '[URL]', text)\n",
    "    # Replace usernames and timestamps\n",
    "    text = re.sub(r'\\(talk\\)|\\d{2}:\\d{2}, \\w+ \\d{1,2}, \\d{4} \\(UTC\\)', '[META]', text)\n",
    "    # Normalize new lines and excessive white spaces\n",
    "    text = text.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee579eb07552aca8",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5bf00b1d955e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.listdir(model_dir):\n",
    "    model.load(model_dir)\n",
    "    print(\"!!!!!!!!!Model loaded!!!!!!!!\")\n",
    "else:\n",
    "    model.train(train_df, val_df)\n",
    "    model.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483a05388e187165",
   "metadata": {},
   "source": [
    "Loading and pre-processing the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3e16f25f7acb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_path = \"data/input/test.csv\"\n",
    "df_test = pd.read_csv(test_dataset_path)\n",
    "df_test['comment_text'] = df_test['comment_text'].fillna(\" \").str.lower()\n",
    "\n",
    "# Load the test labels\n",
    "test_labels_path = \"data/input/test_labels.csv\"\n",
    "df_test_labels = pd.read_csv(test_labels_path)\n",
    "\n",
    "# Merge the test dataset with its labels\n",
    "df_test = df_test.merge(df_test_labels, on='id')\n",
    "\n",
    "# Filter out any rows where the labels might be missing or marked as '-1' (if applicable)\n",
    "df_test = df_test[df_test.toxic != -1]\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "test_dataset = ToxicCommentsDataset(df_test, model.tokenizer, max_len=128)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d0e11385f53abe",
   "metadata": {},
   "source": [
    "Getting Test Predictions and True Label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a82756b5284814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_predictions_and_labels(distilbert_model_instance, data_loader):\n",
    "    distilbert_model_instance.model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    progress_bar = tqdm(range(len(data_loader)), desc=\"Evaluating\")\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            inputs = {\n",
    "                'input_ids': batch['input_ids'].to(device),\n",
    "                'attention_mask': batch['attention_mask'].to(device),\n",
    "            }\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = distilbert_model_instance.model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            predictions.append(logits.detach().cpu().numpy())\n",
    "            true_labels.append(labels.cpu().numpy())\n",
    "\n",
    "            progress_bar.update(1)\n",
    "    progress_bar.close()\n",
    "\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_labels = np.concatenate(true_labels, axis=0)\n",
    "    return predictions, true_labels\n",
    "\n",
    "# Get predictions and true labels\n",
    "predictions, true_labels = get_test_predictions_and_labels(model, test_loader)\n",
    "\n",
    "# Apply a sigmoid function to the predictions since we're dealing with multi-label classification\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "probabilities = sigmoid(torch.tensor(predictions)).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b845c54980b37ff2",
   "metadata": {},
   "source": [
    "Creating predictions.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46b6383082fec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert probabilities to binary predictions using a threshold (e.g., 0.5)\n",
    "#predicted_labels = (probabilities > 0.5).astype(int)\n",
    "predicted_labels = probabilities \n",
    "submission_df = pd.DataFrame(predicted_labels, columns =label_names)\n",
    "\n",
    "# Add the 'id' column from the test DataFrame\n",
    "submission_df.insert(0, 'id', df_test['id'].values)\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "submission_df.to_csv('data/input/predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dfc1bb16fb9fb2",
   "metadata": {},
   "source": [
    "Calculating the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258edf631f1bc723",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
    "print(np.shape(true_labels))\n",
    "roc_aucs = plot_roc_curve(true_labels, probabilities, label_names)\n",
    "\n",
    "# Compute the mean column-wise ROC AUC\n",
    "mean_roc_auc = np.mean(roc_aucs)\n",
    "\n",
    "print(f\"Mean column-wise ROC AUC: {mean_roc_auc}\")\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
